---
title: "Web Scraping Visions Web Page"
author: "Sattelmaier"
date: "5 1 2021"
output: html_document
---
## 1 Project Objectives

This code presents an schedule R script for web scraping. As practical object serves the web presence of one of Germany's leading alterantive music magazines: 'visions.de'. The magazine rates and awards the best music album released in the current week. This means that the award-winning album on this page will change weekly. The goal is to scrape the published album information on a weekly basis and merge it into a single table. 

## 2 Code

### Load packages
```{r}
library(readr)
library(httr)
library(rvest)
library(dplyr)
library(stringr)
library(taskscheduleR)
```

### Get and set working directory
```{r}
getwd()
setwd("C:/Users/maiks/Documents/R/R-Code-Snippets/Web Scraping")
```

### Create empty data frame for first script run
```{r}
df <- data.frame(band = character(),
                 album = character(),
                 release = as.Date(character()),
                 issue = as.numeric(),
                 add_time = as.Date(character()),
                 lead = character(),
                 main = character(),
                 stringsAsFactors=FALSE)
```

### Load .csv file 
Load .csv file from previous script runs.
Skip this code in the first run!
```{r load_data}
df <- read_csv("visions_album_of_the_week", 
               col_types = cols(add_time = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                                release = col_date(format = "%Y-%m-%d"))) 
# read_csv creates an extra column; no convinient solution yet

df <- df[-1]
```
### Load url to scrape
```{r}
visions_url = GET('https://www.visions.de/platten/platte-der-woche/')
status_code(visions_url) # check availability of website: 200 = okay

visions_html <- read_html("https://www.visions.de/platten/platte-der-woche/") # 
class(visions_html) # xml-type variable is created
```

#### Basic scraping code snippets
```{r, include = FALSE}
xml_structure(visions_html) # for overview of the hierarchy
```

```{r, include = FALSE}
visions_html %>%
  html_children() %>%
    html_text() # Extract all the text
```

```{r}
p_node <- visions_html %>%
  html_nodes('p')
p_node
```

```{r}
#children of p_node
p_node %>% html_children()
```

### Get values

#### Band & Album
```{r}
name_raw <- visions_html %>% 
  html_nodes('h1') %>% # 'h1'-argument extracted from web-page html source code; using css method
  html_text() %>%
  str_squish() # remove whitespaces

band <- word(name_raw, 1, sep = "\\-") %>%
          str_squish()
album <- word(name_raw, 2, sep = "\\-") %>%
          str_squish() 
```

Benefits using XPath-method:
- unique node
- applied for complex selectors
- select nodes on properties 

#### Release Date
```{r}
release <- visions_html %>% 
  html_nodes(xpath = '/html/body/div[1]/div[2]/div[4]/div[2]/div[2]/ul/li[1]') %>%  
  html_text() %>%
  str_squish() %>%
  gsub(pattern = "[^0-9.]", replacement = "") %>% # clean date
  as.Date(tryFormats = c("%d.%m.%Y"))
```

#### Mentioned in print issue
```{r}
issue_raw <- visions_html %>% 
  html_nodes(xpath = '/html/body/div[1]/div[2]/div[4]/div[2]/div[2]/ul/li[3]') %>%
  html_text() %>%
  str_squish() %>% # remove whitespaces
  gsub(pattern = "[^0-9]", replacement = "") %>%
  as.numeric()
```

#### Lead of the article
```{r}
lead <- visions_html %>% 
  html_nodes(xpath = '//*[@id="cf"]/div/p/strong') %>% 
  html_text() %>%
  str_squish()
```

#### Main text of the article
```{r}
main <- visions_html %>% 
  html_nodes(xpath = '//*[@id="cf"]/div[position() = 4]') %>% 
  html_text() %>%
  str_squish()
```

#### Update time
```{r}
time <- Sys.time()
```

### Merge information
Merge all Information of the current 'album of the week' into one concise tibble
```{r}
album <- tibble('band' = band,
                'album' = album,
                'release' = release, 
                'issue' = issue_raw, 
                'add_time' = time,
                'lead' = lead, 
                'main' = main)
```

### Append album 
Append this album to the existing tibble, iff it is not yet listed in the table.
```{r, message = FALSE}
if(!(album$band %in% df$band) && !(album$album %in% df$album)){
  df = rbind(album,df)
} else {print('Album is already in the data frame.')}
```

### Save the new dataframe
```{r}
write.csv(df, file = 'visions_album_of_the_week')
```

## 3 Automation 

There exist several solutions to automate this task. One can either use the built-in Windows task scheduler or perform automation with R code using the 'taskscheduleR' package.

The problem of how to load the empty dataframe for the first run remains. Hence, the code should be run the first time manually without the code 'Load CSV file'.

### Using taskscheduleR

First, store the code in a single R script, called 'visionsweeklyscript'. 

```{r}
taskscheduler_create(taskname = "visions_album_weekly", rscript = "C:/Users/maiks/Documents/R/R-Code-Snippets/Web Scraping/visionsweeklyscript.R", 
                     schedule = "WEEKLY", starttime = "09:10", days = c('WED', 'SAT'))
```

Get data.frame of all tasks
```{r}
tasks <- taskscheduler_ls()
str(tasks)
```

Delete Task if necessary
```{r}
taskscheduler_delete(taskname = "visions_album_weekly")
```

